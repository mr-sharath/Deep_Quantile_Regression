# ğŸ“ˆ Deep Quantile Regression for VaR & ES Estimation

## ğŸŒ Project Overview

This project aims to improve the **accuracy and robustness** of market risk measures using deep learning techniques. It targets two key metrics:

* **Value at Risk (VaR)**: Probability-based downside risk estimate.
* **Expected Shortfall (ES)**: Average loss during the worst-case returns beyond VaR.

We use:

* âœ¨ **Quantile Regression with Mogrifier LSTM** for VaR
* âœ¨ **Generative Adversarial Network (GAN)** for ES

---

## ğŸ—‚ï¸ Folder Structure

```
Deep_Quantile_Regression/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                 # Raw financial data (e.g., BLK.csv)
â”‚
â”œâ”€â”€ models/               # Trained PyTorch model files
â”‚   â”œâ”€â”€ quantile_rnn_var.pth
â”‚   â””â”€â”€ gan_generator_es.pth
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ fetch_data.py       # Download financial data from Stooq
â”‚   â”œâ”€â”€ preprocess.py        # Preprocess time series
â”‚   â”œâ”€â”€ train_var_model.py   # Train Mogrifier-LSTM for VaR
â”‚   â”œâ”€â”€ train_es_gan.py     # Train GAN for ES
â”‚   â”œâ”€â”€ evaluate_models.py  # Evaluate both models
â”‚   â””â”€â”€ utils.py            # Helper functions
â”‚
â”œâ”€â”€ README.md             # Project instructions and details
â””â”€â”€ report.md             # Detailed explanation of methods and findings
```

---

## ğŸ’¡ Features & Models

### âœ… VaR Model: Mogrifier-LSTM Quantile Regressor

* Captures temporal dependencies with long memory and volatility clustering.
* Learns the conditional quantile function.
* Based on RNNs with **Mogrifier** linear layers for richer interactions.

**Hyperparameters:**

```python
input_dim = 1
hidden_dim = 32
num_layers = 2
sequence_length = 20
quantile_alpha = 0.05
epochs = 50
learning_rate = 0.001
```

### ğŸ¤– ES Model: GAN-Based Tail Risk Generator

* Conditional GAN learns to generate tail risk samples beyond the VaR.
* Estimates expected shortfall by averaging generated loss scenarios.

**Hyperparameters:**

```python
noise_dim = 10
hidden_dim = 64
num_epochs = 300
batch_size = 64
learning_rate = 0.0002
```

---

## âš™ï¸ How to Setup and Run

### 1. ğŸ“ Clone and Setup

```bash
git clone <repo-url>
cd Deep_Quantile_Regression
pip install -r requirements.txt
```

### 2. ğŸ“Š Download Data

```bash
python scripts/fetch_data.py
```

### 3. ğŸ“ Preprocess Data

```bash
python scripts/preprocess.py
```

### 4. ğŸ‹ï¸ Train VaR Model

```bash
python scripts/train_var_model.py
```

### 5. ğŸ‹ï¸ Train ES Model

```bash
python scripts/train_es_gan.py
```

### 6. âœï¸ Evaluate Models

```bash
python scripts/evaluate_models.py
```

---

## ğŸ”„ Playing with Parameters

* Modify `alpha` for different quantile levels (e.g., 0.01, 0.10)
* Change `hidden_dim`, `sequence_length`, or `noise_dim` in training scripts
* Replace `BLK.csv` with other financial instruments

---

## ğŸ“Š Results Summary

### ğŸŒ Dataset: BlackRock Inc. (BLK) from 2020-05-04 onward

| Metric              | Value   |
| ------------------- | ------- |
| VaR Hit Ratio       | 0.0513  |
| Kupiec Test p-value | 0.8097  |
| Predicted ES        | -0.3366 |
| Historical ES       | 0.5037  |

### âœ… Interpretation:

* **VaR hit ratio** is close to 5%, indicating strong calibration.
* **Kupiec test** confirms statistically consistent performance.
* **ES model** is conservative, indicating realistic tail risk capture.

---

## ğŸ“„ Report Summary

### Goals:

* Improve risk estimation using deep learning.
* Align with financial properties like volatility clustering and long memory.

### Methodologies:

* Quantile loss for VaR
* GAN-based sampling for ES

### Best Settings:

* `hidden_dim = 32`, `seq_len = 20`, `alpha = 0.05`
* `GAN noise_dim = 10`, `epochs = 300`

### Contributions:

* Combines **modern sequence models** with **financial theory**.
* Practical approach to **regulatory risk quantification**.

---

## ğŸš€ Next Steps

* Add LightGBM or GARCH as baseline comparisons
* Use Christoffersen test for further statistical validation
* Extend to multiple stock indices

---

Made by Indu Sai Atla and Sharath Reddy
